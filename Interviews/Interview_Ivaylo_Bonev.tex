\section{Ivaylo Bonev}

\ivo{
Ein typisches Muster sind Datenbankzugriffe. Das ist das was man in alten System am meisten sieht, wenn man Performance-Tuning macht. Diese Programme lesen eine Menge Daten aus einer Datenbank und filtern die relevanten Daten erst im Programm. Stattdessen sollte man das natürlich gleich beim Datenbankzugriff machen. Das ist jetzt zwar nicht typisch für COBOL, aber grundsätzlich für diese Systeme. Bei COBOL ist es so, dass man auch dynamisches SQL schreiben kann, was aber relativ aufwändig ist, weil die Art wie man Code schreibt durch die Bildschirmgröße bzw. Terminalgröße vorgegeben ist. Dabei hat man 72 Spalten zur Verfügung. Das heißt selbst ein kleineres Statement muss man öfter umbrechen und dazu kommt noch, dass die Variablentextlänge auf 160 Zeichen beschränkt ist. Ein längeres Statement muss also in mehreren Variablen gespeichert und später kombiniert werden. Deshalb machen viele einfache Datenbankabfragen mit statischen SQL-Statements, die als quasi Konstante hingeschrieben werden. Für sie ist es dann einfacher im Programm zu filtern. Das kann man auf jeden Fall besser machen. 
\medskip
Grundsätzliches Problem bei COBOL ist, dass man keine Funktionen hat. Man kann also keine Parameter mitgeben. Es ist alles global für das gesamte Programm. Das andere was es schwierig macht ist, dass man dynamische Datenstrukturen nicht so wirklich implementiern kann. Man kann zum Beispiel Pointer auf irgendwelche Strukturen austauschen oder sagen, dass man einen 20MB großen Speicherbereich hat und diesen auf unterschiedliche Art und Weisen interpretiert indem eine Struktur daraufgelegt wird. Also man kann eine Struktur definieren und sagen die redefiniert diesen Speicherbereich. Aber man kann nicht dynamisch Speicher allozieren. Das heißt wenn man ein Array hat muss man immer wissen, was die maximale Anzahl der Elemente ist und das immer statisch reservieren. Das heißt kompliziertere Datenstrukturen umzusetzen wie eine HashMap ist schon schwierig. Eine Möglichkeit wie wir das schon gemacht haben ist, dass man tatsächlich einfach ein Array hat mit einer maximalen Anzahl von Elementen und eine Funktion die von dem Wert einen Index ermittelt. Eine eigene Hashfunktion also. Sowas haben wir schon genutzt. Ansonsten ist es relativ schwierig.
\medskip
Ein weiteres häufiges Muster in COBOL ist, dass 80\% des Codes aus MOVE Befehlen besteht, wo Daten hin und her geschoben werden. Ich weiß nicht ob man das besser machen kann. Das liegt oft daran, dass die Variablen unterschiedlich definiert sind. Es gibt ja zum Beispiel Zahlen für Displayanzeigen und Zahlen für Berechnungen. Damit man von dem einen in den anderen Typ konvertiert muss man diese Daten moven. Das reicht aus. Und oft wird Speicher intern verwaltet. Einmal für das Programm, dann das Statement gegen die Datenbank ausgeführt werden soll werden Teile davon in eine Struktur gemoved die für das SQL passender ist, dann wird das Statement ausgeführt und das Ergebnis landet wieder in anderem Speicher und dieser wird wieder zurückgemoved und damit das Programm dann eine Ausgabe macht gibt es häufig einen weiteren Speicherbereich. Das heißt man sieht ganz viel hin und her mit Daten und das kostet natürlich auch CPU-Zeit.
}

\toni{Ist das dann etwas bei dem du sagen würdest, dass es zwangsweise notwendig ist?}

\ivo{Teilweise schon. Man kann aber überlegen ob man wirklich für Ein- und Ausgabe einen abweichenden Speicherbereich braucht. Aber andererseits ist es auch relativ gut strukturiert, dass man sieht hier ist die Eingabe und die kann abweichend von dem sein, wie die Daten intern verarbeitet werden. Theoretisch ginge auch ein COPY BY REFERENCE indem man einfach den Pointer auf die Datenstruktur ändert. Also wenn man einen riesen Speicherbereich tatsächlich moved dann kopiert es ja alles. Das hatten wir auch wirklich als Optimierungsmöglichkeit, dass wir nur den Pointer von der Struktur geändert haben. Aber da muss man aufpassen, weil man ja tatsächlich die Daten verändert. Nicht, dass eine andere Programmstelle auf die originalen Daten angewiesen ist. }

\toni{Das ist in COBOL aber auch schwierig zu sehen, ob und wo andere Teile auf Daten zugreifen oder?}

\ivo{
    Ja genau, also im Prinzip hast du immer ein Hauptprogramm. Also wenn ein Batch ist oder eine Transaktion dann gibt es ein Hauptprogramm und mehrere Unterprogramme und rein theoretisch können die Unterprogramme auf den Speicherbereich des Hauptprogramms zugreifen, weil die zu einer compile-Einheit kompiliert werden können. Je nachdem wie man es kompiliert. Man kann auch sagen, das Unterprogramm ist reentrant. Das heißt es kann von mehreren Aufrufern verwendet werden. Und dann kann es sein, dass es zwischen den Aufrufen einen Zustand behält wenn man nicht aufpasst und unterschiedliche Transaktionen den gleichen Speicherbereich bekommen und diese sich dann stören würden. Aber es ist ähnlich wie in Java, wenn man ein Singleton habt, der globale Variablen hält die nicht synchronisiert sind. 
\medskip
Grundsätzlich ist die Struktur eines COBOL-Programms ein wenig seltsam. Eigentlich hätte man gar keine Einführung in COBOL gebraucht, weil es ja eine Sprache für Business-Leute ist. Aber das kann man natürlich nicht ändern. Oder um was geht es dir?
}

\toni{Mir geht es darum einen Leitfaden zu erarbeiten, der Java-Entwicklern zeigt wie man COBOL schreibt und liest. Dabei aber auch gleichzeitig zeigt, wie viele Leute COBOL schreiben, was aber eigentlich möglich wäre. Also quasi so Anti-Pattern, die oft verwendet werden, aber eigentlich anders besser gemacht werden könnten. Auf der anderen Seite versuche ich Paradigmen zu untersuchen, die man zum Beispiel aus Java kennt und zu zeigen ob und wenn ja wie diese in COBOL umgesetzt werden können, um COBOL-Entwicklern, die von modernen Sprachen wenig Ahnung haben zu zeigen, dass durch diese Paradigmen unter Umständen der Code effizienter, kürzer oder wie auch immer optimiert werden kann.}

\ivo{
    Ja, das Problem ist einfach, dass man in COBOL nicht objektorientiert programmiert. Es ist alles Prozedural. Das ist einfach ganz anders als in Java. Deshalb haben viele COBOL-Entwickler Schwierigkeiten Java zu verstehen. Die erwarten auch immer ein Hauptprogramm und einen gewissen Fluß, aber das passt einfach nicht zusammen. 

    Andererseits sehen viele COBOL-Programme auf den ersten Blick sehr komisch aus und man denk sich wieso wurde das so gemacht. Aber eigentlich waren das alles sinnvolle Sachen und das wichtigste dabei war einfach Regeln zu etablieren, wie man Sachen benennt und wie grundstätzlich die Struktur ist. In der Regel haben die immer in der MAIN einen Vorbereitungsteil. Also Initialisierung, dann die Hauptverarbeitung, was dann weitere Unterfunktionen aufrufen kann und dann einen Schlussteil, der alles wieder sauber macht. Und wenn man das in allen Programmen einhält, kommt man ziehmlich schnell zurecht. 

    Man kann auch in COBOL eine Art serviceorientierte Programmierung machen indem man sagt, dass ein Programm mit seinen Unterprogrammen ein Service ist und die unterschiedlichen Funktionalitäten die ich anbiete habe ich -- zwar nicht als Methoden, die einfach aufgerufen werden können -- aber als Programm da und mit einer Art Diskriminator-Parameter bzw. Flag das ich mitgebe steuere ich das. Das ganze kann ich über ein COPY mit einem REPLACING auch sinnvoll bennenen und kann dann sagen, dass in diesem Service diese und jene Operationen durchgeführt werden können. Der Verarbeitungsteil ist dann mehr oder weniger ein switch-Statement, das die richtige Funktion aufruft. Bei der Datenübergabe kann man den gleichen Speicherbereich einfach anders nutzen und eine andere Struktur darüberlegen. Das heißt der Speicherbereich wäre ein Object in Java und dann die konkreten Implementierungen in den Funktionen. Also soetwas habe ich öfter gesehen und das ist auch erstaunlich gut eigentlich. Der riesen Nachteil ist, dass man bei Variablen die man weitergibt nicht genau weiß wo diese verändert werden. Aber wenn man sich an die Konventionen hält und sagt, dass jede Funktion ihren eigenen Speicherbereich hat, dann geht das. Das ist auch wieder diese MOVE-Thematik. Dort muss ich auch wieder moven in den Speicherbereich der Funktion, aber dann kann ich einigermaßen sicherstellen, dass keine anderen Zugriffe auf die Daten geschehen. 

    Das meiste was für uns von Bedeutung war hatte mit der Performace zu tun. In COBOL haben wir meistens keine Reengineerings gemacht, im dem Sinne Systeme wartbarer zu machen, sondern meistens Performance-Tuning. Und dabei ist wirklich die Datenbank meistens der Hauptfaktor. Das Thema ist einfach das Filtern oder Joinen in der Datenbank. Häufig sieht man jeweils ein Select für Zeilen die andere verknüpfen und soweiter. Also es liegt hauptsächlich daran, dass man dynamisches SQL schwierig schreiben kann und das bei vielen Kunden auch verboten ist. Die Auswertung des Datenbankbetriebs wird dadurch nämlich erschwert. Man muss nämlich aufpassen, weil dynamisches SQL in der Regel teurer ist als statisches. Das Statement muss erst prepared werden. Aber wenn man alles richtig konfiguriert dann liegt es im Cache und der prepare kostet quasi nichts. Man kann es also optimieren, aber es ist nicht automatisch so und auch trotzdem nicht so schnell wie statisches SQL. Es bringt genau dann Ersparnis, wenn man viele ähnliche Fälle hat und diese alle mit einem Statement abhandeln kann. Ansonsten kann ich auch im statischen SQL joinen nur wenn ich ein weiteres Attribut prüfen muss oder so, dann muss ich das ganze Statement kopieren. Das kann ich nicht zusammenstellen. Aber wiederum wir der Zugriffspfad schon beim kompilieren des Programms ermittelt.

    Häufig wird in einem Programm ziemlich viel gemacht. Das Programm wird also missbraucht um unterschiedlichste Sachen zu machen und dann werden die riesig. Wir hatten auch schon COBOL-Programme die über 10.000 LOC hatten in einer Datei. Das kommt schnell zusammen. Man braucht ja für ein MOVE-Statement schon 2 Zeilen wenn die Variablennamen entsprechend lang sind. Aber sie machen einfach viel in einem Programm weil es einfach schwierig ist Unterprogramme auszulagern. Liegt wahrscheinlich auch sehr an der Tool-Unterstützung. Viele programmieren noch am Host und da hast du einen Editor der wirklich keine 30 Zeilen anzeigt und mehr nicht. Da verliert man einfach schnell die Übersicht. Das macht keinen Sinn dort zu programmieren. Ein Verbesserungsansatz wäre also Programme so klein wie möglich zu halten. Man hat zwar viel overhead und boiler-plate-code der einfach da ist, aber in der Regel ist es das wert. Der Programmieraufwand und die Arbeit sich eine Schnittstelle zu überlegen ist einfach oft ausschlaggebend dafür, dass das leider nicht gemacht wird. 

    Grundsätzlich ist Wiederverwendung sehr schwierig, weil man nur mit dem angesprochenen Fallback, dass Speicherbereich anders interpretiert wird, generisches Verhalten nachahmen kann. Aber es ist nicht einfach. Allerdings könnte man Schnittstellen in eine COPY-Strecke packen und könnte so Sachen auslagern und wiederverwenden. Mir fällt gerade kein Gegenargument ein. Wenn man zum Beispiel sagt man hat eine Sortierroutine die nur einmal implementiert wird und weiß, dass die Datenelemente so und so groß sind dann könnte man diese wiederverwenden. Dass das nicht so oft gemacht wird ist vielleicht so eine Art Anti-Pattern.
}